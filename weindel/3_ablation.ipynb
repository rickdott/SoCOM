{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from hmpai.pytorch.models import *\n",
    "from hmpai.training import split_participants_into_folds\n",
    "from hmpai.pytorch.training import train_and_test\n",
    "from hmpai.pytorch.utilities import set_global_seed\n",
    "from hmpai.pytorch.generators import MultiXArrayProbaDataset\n",
    "from hmpai.data import SAT_CLASSES_ACCURACY\n",
    "from hmpai.pytorch.normalization import *\n",
    "from torchvision.transforms import Compose\n",
    "from hmpai.pytorch.transforms import *\n",
    "from hmpai.pytorch.mamba import *\n",
    "from hmpai.behaviour.sat2 import SAT2_SPLITS\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "Run this after running the ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = Path(\"../logs/model_ablation\")\n",
    "\n",
    "result_files = logs_path.glob(\"*/*.json\")\n",
    "tmp = []\n",
    "ablations = [\n",
    "    \"Linear\",\n",
    "    \"PointConv\",\n",
    "    \"No Spatial\",\n",
    "    \"2 Conv\",\n",
    "    \"3 Conv\",\n",
    "    \"No Pos Enc\",\n",
    "    \"LSTM\",\n",
    "]\n",
    "for file in result_files:\n",
    "    parts = file.name.split(\"_\")\n",
    "    abl = parts[0]\n",
    "    fold = parts[1].split(\".\")[0]\n",
    "    abl_idx = int(abl[8:])\n",
    "    values = {\"ablation\": ablations[abl_idx], \"fold\": fold[4:]}\n",
    "    with open(file, \"r\") as file:\n",
    "        tmp_data = json.load(file)\n",
    "    values[\"result\"] = tmp_data[\"test_kldiv_mean\"]\n",
    "    values[\"runtime\"] = tmp_data[\"runtime\"]\n",
    "    values[\"n_parameters\"] = tmp_data[\"n_parameters\"]\n",
    "    tmp.append(values)\n",
    "data = pd.DataFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = data.groupby(\"ablation\")[[\"result\", \"runtime\", \"n_parameters\"]].mean()\n",
    "means[\"name\"] = [\n",
    "    \"2 convolutional layers\",\n",
    "    \"3 convolutional layers\",\n",
    "    \"LSTM\",\n",
    "    \"Linear\",\n",
    "    \"No positional encoding\",\n",
    "    \"No spatial\",\n",
    "    \"1-D convolution\",\n",
    "]\n",
    "stds = data.groupby(\"ablation\")[[\"result\", \"runtime\", \"n_parameters\"]].std()\n",
    "\n",
    "for i in range(len(means)):\n",
    "    table_str = f\"- & {means.iloc[i, 3]} & {means.iloc[i, 0]:.2f} ({stds.iloc[i, 0]:.2f}) & {means.iloc[i, 1]:.2f} ({stds.iloc[i, 1]:.2f}) & {means.iloc[i, 2]:.0f} \\\\\\\\\"\n",
    "    print(table_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run ablations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)\n",
    "N_FOLDS = len(SAT2_SPLITS[0])\n",
    "\n",
    "data_paths = [DATA_PATH / \"sat2/stage_data_250hz.nc\"]\n",
    "\n",
    "labels = SAT_CLASSES_ACCURACY\n",
    "info_to_keep = [\"event_name\", \"participant\", \"epochs\", \"rt\"]\n",
    "whole_epoch = True\n",
    "subset_cond = None\n",
    "add_negative = True\n",
    "skip_samples = 0\n",
    "cut_samples = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config = {\"n_channels\": 64, \"n_classes\": len(labels), \"n_mamba_layers\": 5}\n",
    "configs = [\n",
    "    # SPATIAL\n",
    "    {\n",
    "        \"use_linear_fe\": True,\n",
    "        \"spatial_feature_dim\": 128,\n",
    "        \"use_conv\": True,\n",
    "        \"conv_kernel_sizes\": [3],\n",
    "        \"conv_in_channels\": [128],\n",
    "        \"conv_out_channels\": [256],\n",
    "        \"conv_concat\": True,\n",
    "        \"use_pos_enc\": True,\n",
    "    },\n",
    "    {\n",
    "        \"use_pointconv_fe\": True,\n",
    "        \"spatial_feature_dim\": 128,\n",
    "        \"use_conv\": True,\n",
    "        \"conv_kernel_sizes\": [3],\n",
    "        \"conv_in_channels\": [128],\n",
    "        \"conv_out_channels\": [256],\n",
    "        \"conv_concat\": True,\n",
    "        \"use_pos_enc\": True,\n",
    "    },\n",
    "    {\n",
    "        \"spatial_feature_dim\": 64,\n",
    "        \"use_conv\": True,\n",
    "        \"conv_kernel_sizes\": [3],\n",
    "        \"conv_in_channels\": [64],\n",
    "        \"conv_out_channels\": [256],\n",
    "        \"conv_concat\": True,\n",
    "        \"use_pos_enc\": True,\n",
    "    },\n",
    "    # TEMPORAL (first one is included in spatial)\n",
    "    # {\n",
    "    #     # \"use_pointconv_fe\": True,\n",
    "    #     # \"spatial_feature_dim\": 128,\n",
    "    #     # \"use_conv\": True,\n",
    "    #     # \"conv_kernel_sizes\": [3],\n",
    "    #     # \"conv_in_channels\": [128],\n",
    "    #     # \"conv_out_channels\": [256],\n",
    "    #     # \"conv_concat\": True,\n",
    "    #     # \"use_pos_enc\": True,\n",
    "    # },\n",
    "    {\n",
    "        \"use_pointconv_fe\": True,\n",
    "        \"spatial_feature_dim\": 128,\n",
    "        \"use_conv\": True,\n",
    "        \"conv_kernel_sizes\": [3, 9],\n",
    "        \"conv_in_channels\": [128, 128],\n",
    "        \"conv_out_channels\": [256, 256],\n",
    "        \"conv_concat\": True,\n",
    "        \"use_pos_enc\": True,\n",
    "    },\n",
    "    {\n",
    "        \"use_pointconv_fe\": True,\n",
    "        \"spatial_feature_dim\": 128,\n",
    "        \"use_conv\": True,\n",
    "        \"conv_kernel_sizes\": [3, 9, 27],\n",
    "        \"conv_in_channels\": [128, 128, 128],\n",
    "        \"conv_out_channels\": [256, 256, 256],\n",
    "        \"conv_concat\": True,\n",
    "        \"use_pos_enc\": True,\n",
    "    },\n",
    "    # POSITIONAL ENCODING\n",
    "    {\n",
    "        \"use_pointconv_fe\": True,\n",
    "        \"spatial_feature_dim\": 128,\n",
    "        \"use_conv\": True,\n",
    "        \"conv_kernel_sizes\": [3, 9],\n",
    "        \"conv_in_channels\": [128, 128],\n",
    "        \"conv_out_channels\": [256, 256],\n",
    "        \"conv_concat\": True,\n",
    "        \"use_pos_enc\": False,\n",
    "    },\n",
    "    # LSTM\n",
    "    {\n",
    "        \"use_pointconv_fe\": True,\n",
    "        \"spatial_feature_dim\": 128,\n",
    "        \"use_conv\": True,\n",
    "        \"conv_kernel_sizes\": [3, 9],\n",
    "        \"conv_in_channels\": [128, 128],\n",
    "        \"conv_out_channels\": [256, 256],\n",
    "        \"conv_concat\": True,\n",
    "        \"use_pos_enc\": True,\n",
    "        \"use_lstm\": True,\n",
    "    },\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    config.update(base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def test_model(config: dict, i: int, from_fold: int = -1) -> None:\n",
    "    data_paths = [DATA_PATH / \"sat2/stage_data_250hz.nc\"]\n",
    "\n",
    "    logs_path = Path(\"../logs/model_ablation\")\n",
    "\n",
    "    set_global_seed(42)\n",
    "    folds = split_participants_into_folds(\n",
    "        data_paths, N_FOLDS, participants_to_use=SAT2_SPLITS[0], shuffle=False\n",
    "    )\n",
    "    ablation_name = f\"ablation{i}\"\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Model {i}\")\n",
    "    for i_fold in range(len(folds)):\n",
    "        if i_fold <= from_fold:\n",
    "            continue\n",
    "        train_folds = deepcopy(folds)\n",
    "        test_fold = train_folds.pop(i_fold)\n",
    "        train_fold = np.concatenate(train_folds, axis=0)\n",
    "        print(f\"\\tFold {i_fold + 1}: test fold: {test_fold}\")\n",
    "\n",
    "        whole_epoch = True\n",
    "        subset_cond = None\n",
    "        add_negative = True\n",
    "        norm_fn = norm_mad_zscore\n",
    "\n",
    "        run_name = f\"{ablation_name}_fold{i_fold}\"\n",
    "\n",
    "        train_data = MultiXArrayProbaDataset(\n",
    "            data_paths,\n",
    "            participants_to_keep=train_fold,\n",
    "            normalization_fn=norm_fn,\n",
    "            whole_epoch=whole_epoch,\n",
    "            labels=labels,\n",
    "            subset_cond=subset_cond,\n",
    "            add_negative=add_negative,\n",
    "            transform=Compose(\n",
    "                [StartJitterTransform(62, 1.0), EndJitterTransform(63, 1.0)]\n",
    "            ),\n",
    "            skip_samples=skip_samples,\n",
    "            cut_samples=cut_samples,\n",
    "            add_pe=config[\"use_pos_enc\"],\n",
    "        )\n",
    "\n",
    "        norm_vars = get_norm_vars_from_global_statistics(train_data.statistics, norm_fn)\n",
    "        class_weights = train_data.statistics[\"class_weights\"]\n",
    "        testval_data = MultiXArrayProbaDataset(\n",
    "            data_paths,\n",
    "            participants_to_keep=test_fold,\n",
    "            normalization_fn=norm_fn,\n",
    "            norm_vars=norm_vars,\n",
    "            whole_epoch=whole_epoch,\n",
    "            labels=labels,\n",
    "            subset_cond=subset_cond,\n",
    "            add_negative=add_negative,\n",
    "            transform=None,\n",
    "            skip_samples=skip_samples,\n",
    "            cut_samples=cut_samples,\n",
    "            add_pe=config[\"use_pos_enc\"],\n",
    "        )\n",
    "\n",
    "        model = build_mamba(config)\n",
    "        n_parameters = count_parameters(model)\n",
    "        start_time = time.time()\n",
    "        test_result = train_and_test(\n",
    "            model,\n",
    "            train_data,\n",
    "            testval_data,\n",
    "            testval_data,\n",
    "            logs_path=logs_path / ablation_name,\n",
    "            workers=12,\n",
    "            batch_size=32,\n",
    "            labels=labels,\n",
    "            lr=0.0001,\n",
    "            use_class_weights=False,\n",
    "            class_weights=class_weights,\n",
    "            whole_epoch=whole_epoch,\n",
    "            epochs=50,\n",
    "            additional_name=run_name,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        config[\"runtime\"] = end_time - start_time\n",
    "        config[\"test_kldiv_mean\"] = test_result[0][\"test_kldiv_mean\"]\n",
    "        config[\"test_kldiv_list\"] = test_result[0][\"test_kldiv_list\"]\n",
    "        config[\"n_parameters\"] = n_parameters\n",
    "        with open(logs_path / ablation_name / f\"{run_name}.json\", \"w\") as out:\n",
    "            json.dump(config, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, config in enumerate(configs):\n",
    "    test_model(config, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
